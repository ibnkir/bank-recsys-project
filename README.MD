# Проект: "Разработка системы рекомендаций банковских продуктов"
## Выполнил: [Кирилл Н.](mailto:ibnkir@yandex.ru)

## Описание проекта
Целью проекта является создание рекомендательной системы, предсказывающей, какие банковские продукты предложить тому или иному клиенту. По заданному клиентскому ID необходимо сделать прогноз,
какие продукты могут быть у клиента на 28.06.2016 в дополнении к тем, чтобы уже были у него на 28.05.2016.
Исходные данные содержат информацию о клиентах и их продуктах за период с 28.01.2015 по 28.05.2016. 

Результаты:
- Исходные данные проанализированы и очищены, 
сгенерированы новые признаки (включая продукты на начало месяца) и 
таргеты (покупка дополнительных продуктов в течение месяца);
- Были оставлены только записи с февраля по июнь каждого года
в соответствии с выявленной сезонностью в активности клиентов;
- Проанализированы данные о популярности продуктов. Для генерации рекомендаций выбраны только 17 
наиболее популярных продуктов из 24 (остальными клиенты практически не пользуются);
-  Для существующих клиентов используются предсказания MultiLabel cb-классификатора,
а новым предлагются самые популярные продукты;
- В процессе обучения для сравнения моделей в качестве метрики используется средний accuracy_score,
а для оценки рекомендательной системы в целом - средний hit-rate @ k.
- Посчитан средний hit-rate @ k для бейзлайна на основе случайных рекомендаций;
- Обучено несколько классификаторов с логированием в MLflow 
(базовый, после отбора признаков и с наилучшими параметрами);
- Развернут веб-сервис на базе FastAPI для обращения к модели и получения рекомендаций;
- Настроен мониторинг с помощью сервисов Prometheus и Grafana. 

Основные инструменты и Python-библиотеки:
- Visual Studio Code
- Jupyter Lab
- MLflow
- scikit-learn 
- catboost
- Docker и Docker Compose 
- FastAPI
- uvicorn
- Prometheus
- Grafana

## Структура репозитория
- `notebooks/eda_ml_notebook.ipynb` - основной Jupyter Notebook для анализа даннных и обучения моделей;
- `requirements.txt` - библиотеки для работы в Jupyter Notebook и запуска сервиса без Docker;
- `input_data/` - папка для исходных данных;
- `clean_data/` - папка для очищенных данных;
- `services/models/` - папка для сериализованных обученных моделей;
- `services/requirements_ml_service.txt` - библиотеки для установки в контейнере;
- `services/Dockerfile_ml_service` - конфигурационный файл для контейнеризации основного сервиса;
- `services/docker-compose.yaml` - конфигурационный файл для контейнеризации всех сервисов в режиме Docker Compose;
- `services/ml_service/recsys_app.py` - исходный код для создания FastAPI-приложения;
- `services/ml_service/recsys_handler.py` - исходный код для обработки запросов к приложению;
- `services/recsys_cli.py` - скрипт для отправки тестовых запросов из командной строки;
- `services/generate_requests.py` - скрипт для имитации нагрузки на основной сервис;
- `services/prometheus/prometheus.yml` - конфигурационный файл для сервиса Prometheus с описанием сборщиков;
- `Monitoring.md` - файл с описанием выбранных метрик;
- `services/dashboard.json` - json-файл с описанием дашборда, построенного в Grafana;
- `services/dashboard.png` - скриншот дашборда.

## Как воспользоваться репозиторием
1. Перейдите в домашнюю папку и склонируйте репозиторий на ваш компьютер
   ```bash
   cd ~
   git clone https://github.com/ibnkir/bank-products-recsys
   ```

2. Загрузите файл `train_ver2.csv.zip` с исходными данными с Yandex-диска по [ссылке](https://disk.yandex.com/d/Io0siOESo2RAaA) и положите его в папку `data/`. 

3. Создайте виртуальное окружение и установите в него необходимые Python-пакеты для работы с ноутбуком
    ```
    python3 -m venv .venv_bank_recsys
    source .venv_bank_recsys/bin/activate
    pip install -r requirements.txt
    ````
 
4. Запустите Jupyter Lab в командной строке
    ```
    jupyter lab --ip=0.0.0.0 --no-browser
    ```

Чтобы не выполнять подготовительный код в Jupyter-ноутбуке и сразу перейти к запуску и тестированию проекта, скачайте файл с обученной моделью по [сслыке]()
    
## Этапы и результаты выполнения проекта

### Трансляция бизнес-задачи в техническую задачу

Поскольку в датасете нет клиентских оценок, будем использовать бинарные метрики точности.

В процессе обучения классификаторов сравниваем их по среднему accuracy_score, 
т.к. мы хотим, чтобы ответы модели максимально точно соответствовали тестовым данным по каждому продукту.
Здесь accuracy_score - это доля всех совпадений, включая 1 и 0, между фактическими и прогнозными векторами добавленных продуктов.

Для сравнения полученной рекомендательной системы с бейзлайном (например, на основе случайных рекомендаций)
будем использовать средний hit-rate, т.к. нам важно, чтобы клиент купил хотя бы один продукт из предложенных.
При этом, игнорируем случаи, когда оба вектора - факт и прогноз - являются нулевыми,  
т.е. когда клиент по факту ничего не купил, и модель тоже ничего не спрогнозировала.
Для таких клиентов не нужно генерировать рекомендации, 
(например, у них уже есть нужные ему продукты, и в данный момент они ничего не купят),
и они не должны ухудшать hit-rate.

### Подготовка инфраструктуры обучения модели
[Кратко опишите, как вы развёртывали MLflow и остальную инфраструктуру для обучения моделей. 
В идеале весь запуск должен быть упакован в shell-скрипт.]

[WIP]

### Анализ данных (EDA)
- Проверили исходные данные на наличие дублирования, пропусков, выбросов, некорректных типов и значений:
    - Удалили признак cod_prov, т.к. он дублирует nomprov;
    - Удалили признаки ult_fec_cli_1t и conyuemp, т.к. у них почти 100% пропусков;
    - В продуктовых колонках ind_nomina_ult1 и ind_nom_pens_ult1 заполнили пропуски нулями 
    и привели их к целому типу;
    - В признаке indrel_1mes привели значения к строковому типу и одному формату;
    - Удалили строки, у которых одновременно незаполнено большое количество признаков;
    - Проверили распредение значений категориальных признаков и удалили tipodom, т.к. он является константным;
    - Все бинарные категориальные признаки со значениями 1/0 привели к целому типу, чтобы не применять
    к ним one-hot кодирование;
    - Строковые значения у числовых признаков и сами эти признаки привели к типу float;
    - Пропуски у числовых признаков заполнили медианами 
    (для renta в разрезе по клиентским сегментам, т.к. они отличаются по уровню доходов), 
    у категориальных - модами. 
    При этом убедились, что взятие этих статистик по всему датасету корректно, 
    т.к. если данные признаки незаполнены в одном месяце, 
    то их нет и в остальных записях соответствующих клиентов;
    - Удалили выбросы у числовых признаков (для renta отдельно по каждому клиентскому сегменту);
- Вместо fecha_alta добавили вещественный признак clientship_years как разницу между датами fecha_dato и fecha_alta,
поделенную на 365 (скольк лет человек является клиентом банка);
- Добавили целые колонки со значениями 1/0 для продуктов на начало месяца 
(вместо изначальных продуктовых колонок с данными на конец месяца) 
и продуктов, купленных в течение месяца (таргеты); 
- Построили динамику покупок по месяцам для "старых" клиентов, которые начали пользоваться услугами банка
до 01.01.2015, чтобы исключить вклад новых клиентов. 
Обнаружили сезонность: с марта активность снижается, потом резко возрастает в июне, 
далее оставшуюся часть года колеблется, достигает пика в феврале и снова начинает падать.
Поэтому для получения июньского прогноза оставили данные с фераля по июнь каждого года;
- Проанализировали популярность продуктов, соответствующие данные
сохранили в файле `pop_ranked_prods.parquet` для формирования рекомендаций новым клиентам;
- Очищенные данные разбили на train (02.2015-06.2015, 02.2016-04.2016) и test (05.2016) 
и сохранили в файлах `clean_data_train.csv.zip` и `clean_data_test.csv.zip`

Код для EDA представлен в файле `notebooks/eda_ml_notebook.ipynb`.


### Обучение моделей

__Базовая модель__

[Проведите эксперименты. Подготовьте пайплайн обработки данных и построения модели. - 
Jupyter Notebook с проведением экспериментов, bin-файл модели.]

[WIP]

__Отбор признаков__

[WIP]

__Подбор гиперпараметров__

[Укажите, какие признаки сгенерировались и как это повлияло на модель. Опишите, что можно увидеть в запусках в MLflow.]

[WIP]



### Развертывание модели

[Кратко опишите процесс запуска веб-сервиса и дополнительной инфраструктуры: баз данных, систем мониторинга, Airflow-графы обновления моделей и т.д. В идеале весь запуск должен быть упакован в shell-скрипт. Оберните модель в веб-сервис, чтобы она отвечала на запросы по API. Также сервис должен подниматься в Docker для удобства выкатки. Нужно получить Python-проект с описанным Dockerfile и описанной структурой API.]

[WIP]

### Мониторинг

[Проследите, чтобы все сервисы в продакшен-среде контролировались метриками. - 
.md-файл с описанием метрик. Метрики должны отправляться из кода проекта.]

[WIP]
