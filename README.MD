# Проект: "Разработка системы рекомендаций банковских продуктов"
## Выполнил: [Кирилл Н.](mailto:ibnkir@yandex.ru)

## Описание проекта
Целью проекта является создание рекомендательной системы, предсказывающей, какие банковские продукты предложить тому или иному клиенту. 

Результаты:
- Проанализированы и очищены исходные данные;
- Сгенерированы новые признаки (включая продукты на начало месяца) и 
таргеты (покупка продуктов в течение месяца);
- Выбрана релевантная метрика - Mean Average Precision @ k (MAP@k);
- Получена метрика для бейзлайна на основе популярности продуктов;
- Обучено несколько моделей catboost-классификатора с логированием в MLflow;
- Развернут веб-сервис на базе FastAPI для получения рекомендаций;
- Настроен мониторинг с помощью сервисов Prometheus и Grafana. 

Основные инструменты и Python-библиотеки:
- Visual Studio Code
- Jupyter Lab
- MLflow
- scikit-learn 
- catboost
- Optuna
- Docker и Docker Compose 
- FastAPI
- uvicorn
- Prometheus
- Grafana

## Структура репозитория
- `notebooks/preparation_steps.ipynb` - основной Jupyter Notebook для анализа даннных и обучения моделей;
- `requirements.txt` - библиотеки для работы в Jupyter Notebook и запуска сервиса без Docker;
- `data/` - папка для исходных и очищенных данных;
- `services/models/` - папка для сериализованных обученных моделей;
- `services/requirements_ml_service.txt` - библиотеки для установки в контейнере;
- `services/Dockerfile_ml_service` - конфигурационный файл для контейнеризации основного сервиса;
- `services/docker-compose.yaml` - конфигурационный файл для контейнеризации всех сервисов в режиме Docker Compose;
- `services/ml_service/fastapi_app.py` - исходный код для создания FastAPI-приложения;
- `services/ml_service/fastapi_handler.py` - исходный код для обработки запросов к приложению;
- `services/tests.py` - скрипт для отправки тестовых запросов;
- `services/generate_requests.py` - скрипт для имитации нагрузки на основной сервис;
- `services/prometheus/prometheus.yml` - конфигурационный файл для сервиса Prometheus с описанием сборщиков;
- `Monitoring.md` - файл с описанием выбранных метрик;
- `services/dashboard.json` - json-файл с описанием дашборда, построенного в Grafana;
- `services/dashboard.png` - скриншот дашборда.

## Как воспользоваться репозиторием
1. Перейдите в домашнюю папку и склонируйте репозиторий на ваш компьютер
   ```bash
   cd ~
   git clone https://github.com/ibnkir/bank-products-recsys
   ```

2. Загрузите файл `train_ver2.csv.zip` с исходными данными по [ссылке](https://disk.yandex.com/d/Io0siOESo2RAaA) и положите его в папку `data/`. 
 
3. Запустите Jupyter Lab в командной строке
    ```
    jupyter lab --ip=0.0.0.0 --no-browser
    ```

4. Чтобы не выполнять подготовительный код в Jupyter-ноутбуке и сразу перейти к запуску и тестированию проекта, скачайте файл с обученной моделью по [сслыке]()
    
## Этапы и результаты выполнения проекта

### Трансляция бизнес-задачи в техническую задачу

Ключевым показателем для банков является риск неисполнения клиентами своих обязательств, 
поэтому прежде всего мы хотим минимизировать количество ложно-положительных рекомендаций (FP),
и значит в качестве основной технической метрики нужно использовать точность (Precision).
Поскольку у нас имеется несколько продуктов и по каждому ставится задача бинарной классификации (предложить продукт или не предложить), то вводим сводную метрику - Mean Average Precision @ 7 (MAP@7):

$$MAP@7 = \frac{1}{|U|} \sum_{u=1}^{|U|} \frac{1}{min(m,7)} \sum_{k=1}^{min(n,7)}P(k),$$

где |U| - кол-во клиентов, n - кол-во рекомендуемых продуктов, m - кол-во добавленных продуктов.


### Подготовка инфраструктуры обучения модели
[Кратко опишите, как вы развёртывали MLflow и остальную инфраструктуру для обучения моделей. 
В идеале весь запуск должен быть упакован в shell-скрипт.]

[WIP]

### Анализ данных (EDA)
- Проверили исходные данные на наличие дублирования, пропусков, выбросов, некорректных типов и значений:
    - Удалили признак cod_prov, т.к. он по сути дублирует nomprov; 
    - Удалили признаки ult_fec_cli_1t и conyuemp, т.к. у них почти 100% пропусков;
    - В продуктовых колонках ind_nomina_ult1 и ind_nom_pens_ult1 заполнили пропуски нулями 
    и привели их к целому типу;
    - В признаке indrel_1mes привели значения к строковому типу и одному формату;
    - Удалили строки, в которых одновременно незаполнены 10 признаков;
    - Проверили распредение значений категориальных признаков, 
    удалили tipodom, т.к. он является константным;
    - Все бинарные категориальные признаки со значениями 1/0 привели к целому типу;
    - Строковые значения у числовых признаков и сами эти признаки привели к типу float;
    - Пропуски у числовых признаков заполнили медианами (в т.ч. у renta - в разрезе по сегментам), 
    у категориальных - модами. 
    При этом убедились, что взятие этих статистик по всему датасету корректно, 
    т.к. если данные признаки незаполнены в одном месяце, 
    то их нет и в остальных записях соответствующих клиентов;
    - Удалили выбросы у числовых признаков (в т.ч. у renta - в разрезе по сегментам);
- Вместо fecha_alta добавили признак clientship_years как разницу между датами fecha_dato и fecha_alta 
(скольк лет человек является клиентом банка),
- Добавили колонками с продуктами на начало месяца и продуктами, которые клиенты купили в течение месяца; 
- Построили динамику покупок по месяцам для "старых" клиентов, которые начали пользоваться услугами банка
до 01.01.2015, чтобы исключить вклад новых клиентов. 
Обнаружили сезонность: с марта активность снижается, потом резко растет в июне, 
далее оставшуюся часть года колеблется, достигает пика в феврале и снова начинает падать.
Поэтому для получения июньского прогноза оставили данные с фераля по июнь каждого года;
- Чтобы лучше отразить месячную сезонность, вместо даты fecha_dato добавили месяц наблюдения;
- Проанализировали популярность продуктов (самым популярными оказались текущие счета), соответствующие данные
сохранили в файле `data/items.parquet` для формирования рекомендаций по умолчанию;
- Очищенные данные разбили на train (02.2015-04.2016) и test (05.2016) 
и сохранили в файлах `data/clean_data_train.csv.zip` и `data/clean_data_test.csv.zip`    

Код для EDA представлен в файле `notebooks/preparation_steps.ipynb`.


### Обучение моделей

__Базовая модель__

[Проведите эксперименты. Подготовьте пайплайн обработки данных и построения модели. - 
Jupyter Notebook с проведением экспериментов, bin-файл модели.]

[WIP]

__Генерация признаков__

[Укажите, какие признаки сгенерировались и как это повлияло на модель. Опишите, что можно увидеть в запусках в MLflow.]

[WIP]

__Отбор признаков__

[WIP]

### Развертывание модели

[Кратко опишите процесс запуска веб-сервиса и дополнительной инфраструктуры: баз данных, систем мониторинга, Airflow-графы обновления моделей и т.д. В идеале весь запуск должен быть упакован в shell-скрипт. Оберните модель в веб-сервис, чтобы она отвечала на запросы по API. Также сервис должен подниматься в Docker для удобства выкатки. Нужно получить Python-проект с описанным Dockerfile и описанной структурой API.]

[WIP]

### Мониторинг

[Проследите, чтобы все сервисы в продакшен-среде контролировались метриками. - 
.md-файл с описанием метрик. Метрики должны отправляться из кода проекта.]

[WIP]
