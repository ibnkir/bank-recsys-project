# Проект: "Разработка системы рекомендаций банковских продуктов"
## Выполнил: [Кирилл Н.](mailto:ibnkir@yandex.ru)

## Описание проекта
- Целью проекта является создание рекомендательной системы, предсказывающей, какие банковские продукты предложить тому или иному клиенту. 
- Были проанализированы и очищены исходные данные, выбраны релевантные метрики, обучено несколько моделей с логированием в MLflow, развернут веб-сервис на базе FastAPI для получения рекомендаций, настроен мониторинг с помощью сервисов Prometheus и Grafana. 
- Рекомендации генерируются с помощью мультиклассового catboost-классификатора. 
Для отбора признаков используется библиотека Optuna.

Основные инструменты и Python-библиотеки:
- Visual Studio Code
- Jupyter Lab
- FastAPI
- uvicorn
- scikit-learn 
- catboost
- MLflow
- Docker и Docker Compose
- Prometheus
- Grafana

## Структура репозитория
- `notebooks/preparation_steps.ipynb` - основной Jupyter Notebook для анализа даннных и обучения моделей;
- `requirements.txt` - библиотеки для работы в Jupyter Notebook и запуска сервиса без Docker;
- `input_data/` - папка для исходных данных;
- `clean_data/` - папка для очищенных данных;
- `services/models/` - папка для сериализованных обученных моделей;
- `services/requirements_ml_service.txt` - библиотеки для установки в контейнере;
- `services/Dockerfile_ml_service` - конфигурационный файл для контейнеризации основного сервиса;
- `services/docker-compose.yaml` - конфигурационный файл для контейнеризации всех сервисов в режиме Docker Compose;
- `services/ml_service/recsys_app.py` - исходный код рекомендательного сервиса;
- `services/tests.py` - скрипт для отправки тестовых запросов;
- `services/prometheus/prometheus.yml` - конфигурационный файл для сервиса Prometheus с описанием сборщиков;
- `Monitoring.md` - файл с описанием выбранных метрик;
- `services/generate_requests.py` - скрипт для имитации нагрузки на основной сервис;
- `services/dashboard.json` - json-файл с описанием дашборда, построенного в Grafana;
- `services/dashboard.png` - скриншот дашборда.

## Как воспользоваться репозиторием
1. Перейдите в домашнюю папку и склонируйте репозиторий на ваш компьютер
   ```bash
   cd ~
   git clone https://github.com/ibnkir/bank-products-recsys
   ```

2. Загрузите файл `train_ver2.csv.zip` с исходными данными по [ссылке](https://disk.yandex.com/d/Io0siOESo2RAaA) и положите его в папку `data/`. 
 
3. Запустите Jupyter Lab в командной строке
    ```
    jupyter lab --ip=0.0.0.0 --no-browser
    ```

4. Чтобы не выполнять подготовительный код в Jupyter-ноутбуке и сразу перейти к запуску и тестированию проекта, скачайте файл с обученной моделью по [сслыке]()
    
## Этапы и результаты выполнения проекта

### Трансляция бизнес-задачи в техническую задачу

Ключевым показателем для банков является риск неисполнения клиентами своих обязательств, 
поэтому прежде всего мы хотим минимизировать количество ложно-положительных рекомендаций (FP),
и значит в качестве основной технической метрики нужно использовать точность (Precision).
Поскольку у нас имеется несколько продуктов и по каждому ставится задача бинарной классификации (предложить продукт или не предложить), то вводим сводную метрику - Mean Average Precision @ 7 (MAP@7):

$$MAP@7 = \frac{1}{|U|} \sum_{u=1}^{|U|} \frac{1}{min(m,7)} \sum_{k=1}^{min(n,7)}P(k),$$

где |U| - кол-во клиентов, n - кол-во рекомендуемых продуктов, m - кол-во добавленных продуктов.



### Подготовка инфраструктуры обучения модели
[Кратко опишите, как вы развёртывали MLflow и остальную инфраструктуру для обучения моделей. 
В идеале весь запуск должен быть упакован в shell-скрипт.]

[WIP]

### Анализ данных (EDA)
- Проверили исходные данные на наличие дублирования, пропусков, некорректных типов и  
значений:
    - Удалили признак nomprov, т.к. он по сути дублирует cod_prov; 
    - Удалили признаки ult_fec_cli_1t и conyuemp, т.к. у них почти 100% пропусков;
    - В двух целевых колонках (ind_nomina_ult1 и ind_nom_pens_ult1) заполнили пропуски нулями 
    и привели их к целому типу;
    - В признаке indrel_1mes привели значения к одному типу и формату;
    - Удалили строки, в которых одновременно незаполнено большое количество признаков;
    - Строковые значения у числовых признаков и сами признаки привели к типу float;
    - Пропуски у числовых признаков заполнили средними значениями, у категориальных - модами. 
    При этом убедились, что взятие этих статистик по всему датасету корректно, 
    т.к. у соответствующих клиентов данные признаки незаполнены во всех месяцах;
- Удалили выбросы у числовых признаков age и antiguedad, при этом большие значения у renta
решили оставить, т.к. они встречаются у значительного количества клиентов, и, скорее всего,
соответствуют премиальному сегменту;
- Обнаружили изменения в характере распределения количества клиентов по времени,
поэтому оставили только данные с июля 2015, что позволило также сократить датасет с ~5Gb до ~3.3Gb;
- Проанализировали популярность продуктов (самыми популярными  оказались текущие счета), 
отранжированные данные по продуктам сохранили в файле `data/items.parquet` для формирования рекомендаций по умолчанию;
- Очищенные данные сохранили в файле `datas/events.parquet`
    
Код для EDA представлен в файле `notebooks/preparation_steps.ipynb`.


### Обучение моделей

__Базовая модель на основе классификации клиентов__

[Проведите эксперименты. Подготовьте пайплайн обработки данных и построения модели. - 
Jupyter Notebook с проведением экспериментов, bin-файл модели.]

[WIP]

__Модель на основе коллаборативной фильтрации без дополнительных признаков__

[Укажите, какие признаки сгенерировались и как это повлияло на модель. Опишите, что можно увидеть в запусках в MLflow.]

[WIP]

__Модель на основе ранжирования по оценкам коллаборативной фильтрации и дополнительным признакам__

### Развертывание модели

[Кратко опишите процесс запуска веб-сервиса и дополнительной инфраструктуры: баз данных, систем мониторинга, Airflow-графы обновления моделей и т.д. В идеале весь запуск должен быть упакован в shell-скрипт. Оберните модель в веб-сервис, чтобы она отвечала на запросы по API. Также сервис должен подниматься в Docker для удобства выкатки. Нужно получить Python-проект с описанным Dockerfile и описанной структурой API.]

[WIP]

### Мониторинг

[Проследите, чтобы все сервисы в продакшен-среде контролировались метриками. - 
.md-файл с описанием метрик. Метрики должны отправляться из кода проекта.]

[WIP]
