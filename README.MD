# Проект: "Разработка системы рекомендаций банковских продуктов"
## Выполнил: [Кирилл Н.](mailto:ibnkir@yandex.ru)

## Описание проекта
Целью проекта является создание рекомендательной системы, предсказывающей, какие банковские продукты предложить тому или иному клиенту. По заданному ID клиента необходимо сделать прогноз, 
какие продукты он купит в июне 2016 г. в дополнении к тем, что у него уже были на 28.05.2016.
Исходные данные содержат помесячную информацию о клиентах и их продуктах за период с 28.01.2015 по 28.05.2016. 

Результаты:
- Проанализировали и очистили исходные данные, 
сгенерировали новые признаки (включая продукты на начало месяца) и 
таргеты (покупка дополнительных продуктов в течение месяца);
- Оставили только записи с февраля по июнь каждого года
в соответствии с выявленной сезонностью в активности клиентов;
- Проанализировали популярность продуктов и оставили 17 из 24 
(остальными клиенты практически не пользуются);
- Рекомендации для существующих клиентов генерируем с помощью MultiLabel cb-классификатора,
новым клиентам, ID которых нет в исходных данных, предлагаем продукты из числа популярных. 
При этом, если модель не выдает никаких рекомендаций клиенту, то относим его
в группу "не беспокоить";
- Обучили несколько классификаторов с логированием в MLflow: 
  - на всех признаках и с параметрами по умолчанию (базовая модель), 
  - после отбора признаков и с теми же параметрами,
  - после подбора гиперпараметров с помощью Randomized Search;
- Для сравнения моделей используем средний accuracy_score,
для сравнения финальной модели с бейзлайном на основе случайных рекомендаций - средний hit-rate @ k.
- Разработали веб-сервис на базе FastAPI для получения рекомендаций по заданному клиентскому ID;
- Мониторинг осуществляется с помощью логирования. 

Основные инструменты и Python-библиотеки:
- Visual Studio Code
- Jupyter Lab
- MLflow
- scikit-learn 
- catboost
- Docker
- FastAPI
- uvicorn
- logging


## Структура репозитория
- `notebooks/eda_ml_notebook.ipynb` - основной Jupyter Notebook для анализа даннных и обучения моделей;
- `requirements.txt` - библиотеки для работы в Jupyter Notebook и запуска сервиса без Docker;
- `data/` - папка для исходных и очищенных данных;
- `services/recs_data/` - папка с готовыми рекомендациями,
включая рекомендации по умолчанию на основе популярных продуктов
и персональные, сгенерированные моделью;
- `models/` - папка для сериализованных обученных моделей;
- `services/requirements_recys_service.txt` - библиотеки для установки в контейнере;
- `services/Dockerfile` - конфигурационный файл для контейнеризации сервиса;
- `services/recsys_service/fastapi_app.py` - исходный код FastAPI-приложения;
- `services/recsys_service/fastapi_handler.py` - исходный код обработчика запросов к FastAPI-приложению;
- `test_service.py` - скрипт для отправки тестовых запросов из командной строки.


## Как воспользоваться репозиторием
1. Перейдите в домашнюю папку и склонируйте репозиторий на ваш компьютер
   ```bash
   cd ~
   git clone https://github.com/ibnkir/bank-products-recsys
   ```

2. Загрузите файл `train_ver2.csv.zip` с исходными данными с Yandex-диска по [ссылке](https://disk.yandex.com/d/Io0siOESo2RAaA) и положите его в папку `data/`. 

3. Создайте виртуальное окружение и установите в него необходимые Python-пакеты для работы с Jupyter-ноутбуком
    ```
    python3 -m venv .venv_bank_recsys
    source .venv_bank_recsys/bin/activate
    pip install -r requirements.txt
    ````
 
4. Запустите Jupyter Lab в командной строке
    ```
    jupyter lab --ip=0.0.0.0 --no-browser
    ```

Чтобы не выполнять подготовительный код в Jupyter-ноутбуке и сразу перейти к запуску и тестированию сервиса, скачайте два файла с готовыми рекомендациями и положите их в папку `services/recs_data/` 
  - Рекомендации по умолчанию на основе популярных продуктов: [pop_ranked_products.parquet](https://disk.yandex.ru/d/qE9gZxkyjxevoA)
  - Персональные рекомендации на 28.06.2016, спрогнозированные моделью: [june_2016_recs.csv.zip](https://disk.yandex.ru/d/4dcIJrLHvrijwA)
    
## Этапы и результаты выполнения проекта

### Трансляция бизнес-задачи в техническую задачу

Т.к. в датасете нет клиентских оценок, используем бинарные метрики точности.

В процессе обучения классификаторов сравниваем их по среднему accuracy_score, 
т.к. мы хотим, чтобы ответы модели максимально точно соответствовали тестовым данным по каждому продукту.
Здесь accuracy_score - это доля всех совпадений, включая 1 и 0, между фактическими и прогнозными векторами добавленных продуктов.

Для сравнения финальной модели с бейзлайном на основе случайных рекомендаций
используем средний hit-rate @ k, т.к. нам важно, чтобы клиент купил хотя бы один продукт из предложенных.
При этом, игнорируем случаи, когда оба вектора - факт и прогноз - являются нулевыми,  
т.е. когда клиент по факту ничего не купил, и модель тоже ничего не спрогнозировала.
Таких клиентов условно относим в группу "не беспокоить" и не предлагаем им никаких рекомендаций,
т.к., скорее всего, они ничего не купят. Поэтому их не нужно учитывать при расчете hit-rate.

### Подготовка инфраструктуры обучения модели
Для запуска MLflow нужно перейти в терминале в папку `/mlflow_server` репозитория и выполнить команду 
```
sh run_mlflow_server.sh
```
После этого в соотвествующем разделе ноутбука установить параметры MLflow Tracking Server и MLflow Model Registry и задать имя эксперимента (используем один эксперимент на все этапы, которым будут соответствовать разные запуски).

### Анализ данных (EDA)
- Проверили исходные данные на наличие дублирования, пропусков, выбросов, некорректных типов и значений:
    - Удалили признак cod_prov, т.к. он дублирует nomprov;
    - Удалили признаки ult_fec_cli_1t и conyuemp, т.к. у них почти 100% пропусков;
    - В продуктовых колонках ind_nomina_ult1 и ind_nom_pens_ult1 заполнили пропуски нулями 
    и привели их к целому типу;
    - В признаке indrel_1mes привели значения к строковому типу и одному формату;
    - Удалили строки, у которых одновременно незаполнено большое количество признаков;
    - Проверили распредение значений категориальных признаков и удалили tipodom, т.к. он является константным;
    - Все бинарные категориальные признаки со значениями 1/0 привели к целому типу, чтобы не применять
    к ним one-hot кодирование;
    - Строковые значения у числовых признаков и сами эти признаки привели к float;
    - Пропуски у числовых признаков заполнили медианами 
    (для renta в разрезе по клиентским сегментам, т.к. они отличаются по уровню доходов), 
    у категориальных - модами. 
    При этом убедились, что взятие этих статистик по всему датасету корректно, 
    т.к. если данные признаки незаполнены в одном месяце, 
    то их нет и в остальных записях соответствующих клиентов;
    - Удалили выбросы у числовых признаков (для renta также отдельно по каждому клиентскому сегменту);
- Вместо fecha_alta добавили вещественный признак clientship_years как разницу между датами fecha_dato и fecha_alta,
поделенную на 365 (скольк лет человек является клиентом банка);
- Добавили целые колонки со значениями 1/0 для продуктов на начало месяца 
(вместо изначальных продуктовых колонок с данными на конец месяца) 
и продуктов, купленных в течение месяца (таргеты); 
- Построили динамику покупок по месяцам для "старых" клиентов, которые начали пользоваться услугами банка
до 01.01.2015, чтобы исключить вклад новых. 
Обнаружили сезонность: с марта активность снижается, потом резко возрастает в июне, 
далее оставшуюся часть года колеблется, достигает пика в феврале и снова начинает падать.
Поэтому для получения июньского прогноза оставили данные с фераля по июнь каждого года;
- Проанализировали популярность продуктов, соответствующие данные
сохранили в файле `pop_ranked_products.parquet` для формирования рекомендаций новым клиентам;
- Очищенные данные разбили на train (02.2015-06.2015, 02.2016-04.2016) и test (05.2016) 
и сохранили в файлах `clean_data_train.csv.zip` и `clean_data_test.csv.zip` соответственно.

Код для EDA представлен в файле `notebooks/eda_ml_notebook.ipynb`.


### Обучение моделей и получение рекомедаций

1. Базовая модель

Обучили cb-классификатор с функцией потерь MultiLogloss на всех исходных и сгенерированных признаках
(за исключением продуктов на конец месяца) с гиперпараметрами по умолчанию:
{'learning_rate': 0.5, 'l2_leaf_reg': 3, 'iterations': 15, 'depth': 6}

Средний accuracy_score при валидации на тестовых данных: 0.997663

2. Отбор признаков

Проверили важность признаков у предыдущей модели и отбросили самые незначимые:
- sexo, 
- ind_nuevo, 
- indrel, 
- ind_actividad_cliente,
- age,
- antiguedad,
- clientship_years

При обучении модели на отобранных признаках с теми же гиперпараметрами
ошибка уменьшилась, но при этом средний accuracy_score также снизился: 0.997536

3. Подбор гиперпараметров

С помощью Randomized Search подобрали гиперпараметры для базовой модели:
{'learning_rate': 0.005, 'l2_leaf_reg': 5, 'iterations': 10, 'depth': 6}

Средний accuracy_score остался меньше, чем у базовой модели: 0.997537,
поэтому используем базовую в качестве финальной.

4. Сравнение с бейзлайном

Сравниваем финальную модель с бейзлайном на основе случайных рекомендаций по среднему hit-rate @ 7.
Метрика у модели оказалась почти в 10 раз выше:
- Модель: 0.127429
- Бейзлайн: 0.015445

5. Получение рекомендаций на 28.06.2016 г.

С помощью финальной модели сгенерировали прогноз покупки продуктов в июне, используя признаки 
и продукты во владении на конец мая. Сохранили ID клиентов и прогнозные колонки 
в файле `june_2016_recs.csv.zip`.
При этом оставили строки, где все прогнозные колонки нулевые, чтобы отличать существующих клиентов от новых.  

### Запуск и тестирование сервиса

Перед запуском убедитесь, что в папке `services/recs_data` находятся все необходимые файлы с готовыми рекомендациями (см. выше)

1. Запуск

Запуск в виртуальном окружении
- Перейти на терминале в папку `services/`    
- Запустить сервер uvicorn:
  ```
  uvicorn recsys_service.fastapi_app:app --reload --port 1702 --host 0.0.0.0
  ```

Запуск в Docker-контейнере
- Перейти на терминале в папку `services/`
- Собрать и запустить контейнер:
  ```
  docker image build . --file Dockerfile --tag bank_recsys_proj:recsys_service
  docker container run --name recsys_service --publish 4601:1702 --volume=./recs_data:/recsys_app/recs_data 
  ```

2. Тестирование

Отправлять тестовые запросы можно в Swagger UI, перейдя по ссылкеhttp://localhost:1702/docs,
либо в командной строке c помощью скрипта `test_services.py`

Чтобы воспользоваться тестовым скриптом, откройте новый терминал, перейдите на нем в папку проекта и выполните команды, 
соответствующие различным тестовым примерам, как показано ниже:

- Существующий клиент с user_id = 1351337, для которого есть рекомендации<br>
```python test_service.py --user_id 1351337 --top_k 7```
- Существующий клиент с user_id = 418977, для которого нет рекомендаций (группа "не беспокоить")<br>
```python test_service.py --user_id 418977 --top_k 7```
- Новый клиент без user_id<br>
```python test_service.py --top_k 7```
- Клиент с несуществующим user_id (считаем его новым клиентом)<br>
```python test_service.py --user_id 0 --top_k 7```


### Мониторинг 

Для мониторинга используется логирование в тестовый лог-файл `test_service.log` и в поток `uvicorn.error`. В первый записываются ответы на запросы к сервису,
во второй - системные сообщения, а также следующие бизнес-метрики:
- Количество запросов от существующих клиентов с рекомендациями;
- Количество запросов от существующих клиентов без рекомендаций (группа "не беспокоить");
- Количество запросов от новых клиентов.

### Остановка сервиса

Если сервис запускался в виртуальном окружении, то достаточно остановить uvicorn в соответствующем терминале с помощью комбинации клавиш Ctrl+C.

Если сервис запускался с помощью Docker, то для остановки и удаления контейнера по окончании работы необходимо выполнить следующие команды:
  ```
  docker stop recsys_service
  docker rm recsys_service
  ```

Также при необходимости можно удалить образ контейнера, выполнив следующие действия:
- Находим ID образа
  ```
  docker images
  ```

- Удаляем образ по найденному ID
  ```
  docker rmi -f <id вашего образа>
  ```
